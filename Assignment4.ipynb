{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import tracery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"The digital cut-up revisited. \n",
    "In assignment #2, the tools available to you for cutting up and rearranging \n",
    "texts relied only on information present in the character data itself. \n",
    "Since then, we’ve learned several methods for incorporating outside \n",
    "information concerning syntax (i.e. with spaCy) and semantics \n",
    "(i.e., word vectors) into what we “know” about a text in question. \n",
    "Adapt your original digital cut-up assignment, making use of one of\n",
    "these new sources of information. What new aesthetic possibilities are made\n",
    "available if the unit of the cut-up can be a type of syntactic unit (instead of \n",
    "words, lines, characters), and if stretches of text can be algorithmically \n",
    "selected not at random, but based on their meaning?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "words = [w for w in list(doc) if w.is_alpha]\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "entities = list(doc.ents)\n",
    "\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]\n",
    "adjs = [w for w in words if w.pos_ == \"ADJ\"]\n",
    "advs = [w for w in words if w.pos_ == \"ADV\"]\n",
    "nums=[w for w in words if w.pos_ == \"NUM\"]\n",
    "adps=[w for w in words if w.pos_ == \"ADP\"]\n",
    "auxs =[w for w in words if w.pos_ == \"AUX\"]\n",
    "conjs=[w for w in words if w.pos_ == \"SCONJ\"]\n",
    "dets=[w for w in words if w.pos_ == \"DET\"]\n",
    "nouns  = [i.text.lower() for i in nouns]\n",
    "verbs  = [i.text.lower() for i in verbs]\n",
    "adjs  = [i.text.lower() for i in adjs]\n",
    "advs  = [i.text.lower() for i in advs]\n",
    "adps=[i.text.lower() for i in adps]\n",
    "auxs =[i.text.lower() for i in auxs]\n",
    "conjs=[i.text.lower() for i in conjs]\n",
    "dets=[i.text.lower() for i in dets]\n",
    "nums=[i.text.lower() for i in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "adps=list(set(adps))\n",
    "conjs=list(set(conjs))\n",
    "dets=list(set(dets))\n",
    "auxs=list(set(auxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if', 'since']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use be incorporating these assignment.\n",
      "A type of question revisited.\n",
      "The up in sources making.\n",
      "These digital assignment can adapt the up in up.\n",
      "Unit are cutting a digital text.\n",
      "The new words cutting word.\n",
      "These available characters are relied these question about use.\n",
      "A text cut.\n",
      "Unit relied.\n",
      "The question about question relied these digital information.\n"
     ]
    }
   ],
   "source": [
    "rules={\n",
    "    \"origin\":[\n",
    "        \"#thing.capitalize# #verb#.\",\n",
    "        \"#thing.capitalize# #aux# #verb#.\",\n",
    "        \"#thing.capitalize# #verb# #thing#.\",\n",
    "        \"#thing.capitalize# #aux# #verb# #thing#.\"\n",
    "             ],\n",
    "    \"thing\":[\n",
    "        \"#det# #noun#\",\n",
    "        \"#noun#\",\n",
    "        \"#det# #adj# #noun#\",\n",
    "        \"#det# #noun# #adp# #noun#\" \n",
    "        \n",
    "    ],\n",
    "    \"noun\":nouns,\n",
    "    \"adj\":adjs,\n",
    "    \"verb\":verbs,\n",
    "    \"aux\":auxs,\n",
    "    \"det\":dets,\n",
    "    \"adp\":adps\n",
    "    \n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "for i in range(10):\n",
    "    print(grammar.flatten(\"#origin#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
